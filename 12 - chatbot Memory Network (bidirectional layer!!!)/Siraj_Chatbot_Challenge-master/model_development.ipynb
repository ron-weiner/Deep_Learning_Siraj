{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers import Input, Activation, Dense, Permute, Dropout, add, dot, concatenate\n",
    "from keras.layers import LSTM, TimeDistributed, Conv1D\n",
    "from keras.layers.wrappers import Bidirectional\n",
    "\n",
    "\n",
    "\n",
    "from keras.utils import vis_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from seya.layers.ntm import NeuralTuringMachine as NTM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers import Input, Activation, Dense, Permute, Dropout, add, dot, concatenate\n",
    "from keras.layers import LSTM, TimeDistributed\n",
    "from keras.layers import Conv1D, MaxPool1D\n",
    "from keras.layers.wrappers import Bidirectional\n",
    "\n",
    "class ConfigurableNetwork:\n",
    "    defaultfile = 'default.cfg'\n",
    "    def __init__(self, modelname):\n",
    "        self._modelname = modelname\n",
    "\n",
    "        # Set up the environment. load config file if it is there, if not, then create it form default\n",
    "        # Load the weights\n",
    "\n",
    "        # existential question: should this contain all of the handling for fitting and callbacks?\n",
    "        # yeah I think that makes sense. One stop shop for configs, weights, and logging.\n",
    "\n",
    "\n",
    "    def setup(self):\n",
    "        pass\n",
    "\n",
    "    @property\n",
    "    def modelname(self): return self._modelname\n",
    "\n",
    "\n",
    "\n",
    "class QueryableNet:\n",
    "    def __init__(self, vocab_size=22, story_maxlen=68, query_maxlen=4):\n",
    "        self.model = None\n",
    "        self.vocab_size = vocab_size\n",
    "        self.query_maxlen = query_maxlen\n",
    "        self.story_maxlen = story_maxlen\n",
    "\n",
    "\n",
    "    def query(self, storyvec, queryvec):\n",
    "        storyvec = storyvec.reshape((-1, self.story_maxlen))\n",
    "        queryvec = queryvec.reshape((-1, self.query_maxlen))\n",
    "        ans = self.model.predict([storyvec, queryvec])\n",
    "        return ans\n",
    "\n",
    "class DeepMemNet(QueryableNet):\n",
    "    \"\"\"\n",
    "    DeepMemNet for the Facebook bAbI context task.\n",
    "\n",
    "    Model notes:\n",
    "    Single context task:\n",
    "      Regular LSTM (accuracy/val_acc):\n",
    "        Run 1\n",
    "            47/50% @ 7 epochs\n",
    "            72/70% @ 49 epochs\n",
    "            86/80% @ 61 epochs\n",
    "            95/90% @ 88 epochs\n",
    "        Run 2\n",
    "\n",
    "\n",
    "\n",
    "      Bidirectional LSTM:\n",
    "        Run 1\n",
    "            50%/50% @ 6\n",
    "            81%/80% @ 34\n",
    "            87%/86% @ 48 (peak valacc)\n",
    "            90%/86% @ 60 epochs - minor overfitting\n",
    "\n",
    "        I think parameters were not configured right, these might be Single LSTM! need to rerun everything >_<\n",
    "        Run 2\n",
    "            73/71% @ 44\n",
    "            83/80% @ 53\n",
    "            94/90% @ 75\n",
    "        Run 3\n",
    "            71/70% @ 41\n",
    "            83/80% @ 50\n",
    "            94/90% @ 76\n",
    "\n",
    "      Bidirectional + extra forward LSTM:\n",
    "        55%/??% @ 80 (stalls)\n",
    "\n",
    "      TDDense + Bidirectional:\n",
    "        Run 1:\n",
    "            76/73% @ 37\n",
    "            80/80% @ 41\n",
    "            91/90% @ 54 - new record!!\n",
    "\n",
    "    Double Context task:\n",
    "      Regular:\n",
    "        50%/??% @ 35 epochs\n",
    "        67%/??% @ 80 epochs\n",
    "        70%/??% @ 100\n",
    "        80%/??% @ 192\n",
    "        84.7%/??% @ 260\n",
    "\n",
    "      Bidirectional:\n",
    "        50%/??% @ 26 epochs\n",
    "        70%/??% @ 48 epochs - improvement!\n",
    "        80%/??% @ 68 epochs - super improvement!\n",
    "        90%/??% @ 110 epochs - smokin'!\n",
    "        95%/??% @ 148 epochs - starting to level off\n",
    "        97%/??% @ 200 epochs - i think it's starting to overfit\n",
    "    \"\"\"\n",
    "    # todo: add performance logging\n",
    "    def __init__(self, vocab_size=22, story_maxlen=68, query_maxlen=4, n_lstm=32, bidirect=True, tdd=True,\n",
    "                 matchconv=False, permute=False):\n",
    "        \"\"\"\n",
    "        DeepMemNet\n",
    "\n",
    "        Param note - changing parameters will require new model file (duh) - this isn't automatic yet\n",
    "        :param vocab_size:\n",
    "        :param story_maxlen:\n",
    "        :param query_maxlen:\n",
    "        :param n_lstm:\n",
    "        :param bidirect:\n",
    "        \"\"\"\n",
    "\n",
    "        # todo: config file for model hyperparams with logging link\n",
    "\n",
    "        # self.vocab_size = vocab_size\n",
    "        # self.story_maxlen = story_maxlen\n",
    "        # self.query_maxlen = query_maxlen\n",
    "        super().__init__(vocab_size=vocab_size, story_maxlen=story_maxlen, query_maxlen=query_maxlen)\n",
    "        # placeholders\n",
    "        input_sequence = Input((story_maxlen,), name='InputSeq')\n",
    "        question = Input((query_maxlen,), name='Question')\n",
    "\n",
    "        # Encoders - initial encoders are pretty much just projecting the input into a useful space\n",
    "        # not much need to optimize here really\n",
    "        input_encoder_m = Sequential(name='InputEncoderM')\n",
    "        input_encoder_m.add(Embedding(input_dim=vocab_size,\n",
    "                                      output_dim=64, name='InEncM_Embed'))\n",
    "        input_encoder_m.add(Dropout(0.3))\n",
    "        # output: (samples, story_maxlen, embedding_dim)\n",
    "\n",
    "        # embed the input into a sequence of vectors of size query_maxlen\n",
    "        input_encoder_c = Sequential(name='InputEncoderC')\n",
    "        input_encoder_c.add(Embedding(input_dim=vocab_size,\n",
    "                                      output_dim=query_maxlen, name='InEncC_Embed'))\n",
    "        input_encoder_c.add(Dropout(0.3))\n",
    "        # output: (samples, story_maxlen, query_maxlen)\n",
    "\n",
    "        # embed the question into a sequence of vectors\n",
    "        question_encoder = Sequential(name='QuestionEncoder')\n",
    "        question_encoder.add(Embedding(input_dim=vocab_size,\n",
    "                                       output_dim=64,\n",
    "                                       input_length=query_maxlen, name='QuesEnc_Embed'))\n",
    "        question_encoder.add(Dropout(0.3))\n",
    "        # output: (samples, query_maxlen, embedding_dim)\n",
    "\n",
    "        # encode input sequence and questions (which are indices)\n",
    "        # to sequences of dense vectors\n",
    "        input_encoded_m = input_encoder_m(input_sequence)\n",
    "        input_encoded_c = input_encoder_c(input_sequence)\n",
    "        question_encoded = question_encoder(question)\n",
    "\n",
    "        # compute a 'match' between the first input vector sequence\n",
    "        # and the question vector sequence\n",
    "        # shape: `(samples, story_maxlen, query_maxlen)`\n",
    "        match = dot([input_encoded_m, question_encoded], axes=(2, 2), name='Match')\n",
    "        match = Activation('softmax')(match)\n",
    "\n",
    "        if matchconv:\n",
    "            match = Conv1D(query_maxlen, 4, padding='same')(match)\n",
    "\n",
    "        # add the match matrix with the second input vector sequence\n",
    "        response = add([match, input_encoded_c], name='ResponseAdd')  # (samples, story_maxlen, query_maxlen)\n",
    "        response = Permute((2, 1), name='ResponsePermute')(response)  # (samples, query_maxlen, story_maxlen)\n",
    "\n",
    "        # concatenate the match matrix with the question vector sequence\n",
    "        answer = concatenate([response, question_encoded], name='AnswerConcat')\n",
    "\n",
    "        # Trying to feed in the long axis as the timestep causes the GPU to get very angry.\n",
    "        # It would appear it causes it to start thrashing memory\n",
    "        if permute:\n",
    "            answer = Permute((2, 1), name='AnswerPermute')(answer)  # (samples, story_maxlen, query_maxlen)\n",
    "\n",
    "\n",
    "        # Let's try with a time distributed dense before the RNN\n",
    "        if tdd:\n",
    "            answer = TimeDistributed(Dense(n_lstm, name='Answer_TDD'))(answer)\n",
    "\n",
    "        # Bidirectional LSTM for better context recognition, plus an additional one for flavor\n",
    "        lstm_rev = Bidirectional(LSTM(n_lstm, return_sequences=True, name='Ans_LSTM_reverse'))\n",
    "        lstm_for = Bidirectional(LSTM(n_lstm, return_sequences=False, name='Ans_LSTM_forward'))\n",
    "        if bidirect:\n",
    "            answer = lstm_rev(answer)  # \"reverse\" pass goes first\n",
    "        answer = lstm_for(answer)\n",
    "        # answer = LSTM(n_lstm, name='Ans_LSTM_3)(answer) # Extra LSTM completely runs out of steam at 55% acc! Bidirectional seems to help\n",
    "\n",
    "\n",
    "\n",
    "        # one regularization layer -- more would probably be needed.\n",
    "        answer = Dropout(0.3, name='Answer_Drop')(answer)\n",
    "        answer = Dense(vocab_size, name='Answer_Dense')(answer)  # (samples, vocab_size)\n",
    "        # we output a probability distribution over the vocabulary\n",
    "        answer = Activation('softmax')(answer)\n",
    "\n",
    "        # build the final model\n",
    "        model = Model([input_sequence, question], answer)\n",
    "        model.compile(optimizer='rmsprop', loss='categorical_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "        self.model = model\n",
    "\n",
    "    # def query(self, storyvec, queryvec):\n",
    "    #     storyvec = storyvec.reshape((-1, self.story_maxlen))\n",
    "    #     queryvec = queryvec.reshape((-1, self.query_maxlen))\n",
    "    #     ans = self.model.predict([storyvec, queryvec])\n",
    "    #     return ans\n",
    "\n",
    "\n",
    "class ConvoLSTM(QueryableNet):\n",
    "    def __init__(self, vocab_size=22, story_maxlen=68, query_maxlen=4, n_lstm=32, bidirect=True, tdd=True,\n",
    "                 matchconv=False, permute=False):\n",
    "        super().__init__(vocab_size=vocab_size, story_maxlen=story_maxlen, query_maxlen=query_maxlen)\n",
    "\n",
    "        dropout_rate = 0.2\n",
    "        embed_vector_len = 64\n",
    "        n_filter = 120\n",
    "        filter_length = 5\n",
    "\n",
    "        input_sequence = Input((story_maxlen,), name='InputSeq')\n",
    "        question = Input((query_maxlen,), name='Question')\n",
    "#         input_sequence = Activation('linear')(input_sequence)\n",
    "#         question = Activation('linear')(question)\n",
    "        \n",
    "#         model = Model()\n",
    "        model = concatenate([input_sequence, question], name='AnswerConcat')\n",
    "        model = Embedding(vocab_size, embed_vector_len)(model)\n",
    "        model = Conv1D(filters=n_filter, kernel_size=filter_length, padding='valid', activation='relu')(model)\n",
    "        model = MaxPool1D(pool_size=2)(model)\n",
    "        model = Dropout(dropout_rate)(model)\n",
    "#         model = LSTM(n_lstm)(model)\n",
    "\n",
    "        # Let's try with a time distributed dense before the RNN\n",
    "        if tdd:\n",
    "            model.add(TimeDistributed(Dense(n_lstm, name='Answer_TDD')))\n",
    "\n",
    "        # Bidirectional LSTM for better context recognition, plus an additional one for flavor\n",
    "        lstm_rev = Bidirectional(LSTM(n_lstm, return_sequences=True, name='Ans_LSTM_reverse'))\n",
    "        lstm_for = Bidirectional(LSTM(n_lstm, return_sequences=False, name='Ans_LSTM_forward'))\n",
    "        if bidirect:\n",
    "            model = lstm_rev(model)  # \"reverse\" pass goes first\n",
    "        model = lstm_for(model)\n",
    "#         model = LSTM(n_lstm)(model)\n",
    "        model = Dropout(dropout_rate)(model)\n",
    "        output = Dense(vocab_size, activation='sigmoid')(model)\n",
    "        model = Model([input_sequence, question], output)\n",
    "        model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "        self.model = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dmn = DeepMemNet(bidirect=False, tdd=False)\n",
    "dmn = ConvoLSTM(bidirect=False, tdd=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Failed to import pydot. You must install pydot and graphviz for `pydotprint` to work.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\HILA\\Anaconda3\\envs\\py35\\lib\\site-packages\\pydot.py\u001b[0m in \u001b[0;36mcreate\u001b[1;34m(self, prog, format)\u001b[0m\n\u001b[0;32m   1877\u001b[0m                 \u001b[0mshell\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1878\u001b[1;33m                 stderr=subprocess.PIPE, stdout=subprocess.PIPE)\n\u001b[0m\u001b[0;32m   1879\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\HILA\\Anaconda3\\envs\\py35\\lib\\subprocess.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds)\u001b[0m\n\u001b[0;32m    675\u001b[0m                                 \u001b[0merrread\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrwrite\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 676\u001b[1;33m                                 restore_signals, start_new_session)\n\u001b[0m\u001b[0;32m    677\u001b[0m         \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\HILA\\Anaconda3\\envs\\py35\\lib\\subprocess.py\u001b[0m in \u001b[0;36m_execute_child\u001b[1;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, unused_restore_signals, unused_start_new_session)\u001b[0m\n\u001b[0;32m    954\u001b[0m                                          \u001b[0mcwd\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 955\u001b[1;33m                                          startupinfo)\n\u001b[0m\u001b[0;32m    956\u001b[0m             \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] The system cannot find the file specified",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\HILA\\Anaconda3\\envs\\py35\\lib\\site-packages\\keras\\utils\\vis_utils.py\u001b[0m in \u001b[0;36m_check_pydot\u001b[1;34m()\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[1;31m# to check the pydot/graphviz installation.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m         \u001b[0mpydot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpydot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\HILA\\Anaconda3\\envs\\py35\\lib\\site-packages\\pydot.py\u001b[0m in \u001b[0;36mcreate\u001b[1;34m(self, prog, format)\u001b[0m\n\u001b[0;32m   1882\u001b[0m                     '\"{prog}\" not found in path.'.format(\n\u001b[1;32m-> 1883\u001b[1;33m                         prog=prog))\n\u001b[0m\u001b[0;32m   1884\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mException\u001b[0m: \"dot.exe\" not found in path.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-2c5fd394d4a0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mvis_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdmn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'model.png'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshow_shapes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\HILA\\Anaconda3\\envs\\py35\\lib\\site-packages\\keras\\utils\\vis_utils.py\u001b[0m in \u001b[0;36mplot_model\u001b[1;34m(model, to_file, show_shapes, show_layer_names, rankdir)\u001b[0m\n\u001b[0;32m    129\u001b[0m             \u001b[1;34m'LR'\u001b[0m \u001b[0mcreates\u001b[0m \u001b[0ma\u001b[0m \u001b[0mhorizontal\u001b[0m \u001b[0mplot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \"\"\"\n\u001b[1;32m--> 131\u001b[1;33m     \u001b[0mdot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_to_dot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshow_shapes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshow_layer_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrankdir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m     \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mextension\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplitext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mto_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mextension\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\HILA\\Anaconda3\\envs\\py35\\lib\\site-packages\\keras\\utils\\vis_utils.py\u001b[0m in \u001b[0;36mmodel_to_dot\u001b[1;34m(model, show_shapes, show_layer_names, rankdir)\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m     \u001b[0m_check_pydot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m     \u001b[0mdot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpydot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[0mdot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'rankdir'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrankdir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\HILA\\Anaconda3\\envs\\py35\\lib\\site-packages\\keras\\utils\\vis_utils.py\u001b[0m in \u001b[0;36m_check_pydot\u001b[1;34m()\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[1;31m# pydot raises a generic Exception here,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[1;31m# so no specific class can be caught.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m         raise ImportError('Failed to import pydot. You must install pydot'\n\u001b[0m\u001b[0;32m     28\u001b[0m                           ' and graphviz for `pydotprint` to work.')\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: Failed to import pydot. You must install pydot and graphviz for `pydotprint` to work."
     ]
    }
   ],
   "source": [
    "vis_utils.plot_model(dmn.model, 'model.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
